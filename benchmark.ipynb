{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd4de2c",
   "metadata": {},
   "source": [
    "## Benchmarking nn.Linear vs nd.Linear in a Sequence To Sequence Machine Translation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa08f4e",
   "metadata": {},
   "source": [
    "### Overview\n",
    "**this is my application to Ensemble AI's ML research intern & ML engineering intern positions** \n",
    "\n",
    "- We will be implementing a Sequence To Sequence model for English to Chinese machine translation. \n",
    "- The attention mechanism we will be implementing will be Luong Attention, general form, as it makes use of another Linear layer. \n",
    "- We will run 2 experiments benchmarking nn.Linear vs nd.Linear:\n",
    "\n",
    "1. **Performance Benchmarking**\n",
    "We will compare final performance between the Seq2Seq models using nn.Linear and nd.Linear, keeping model size the same. \n",
    "\n",
    "2. **Parameter size analysis**\n",
    "We will evaluate whether a Seq2Seq model using nd.Linear will perform similarly to the same model architecture using nn.Linear, but with a lower parameter count; specifically, the hidden dim will be 128 in the nn.Linear implementation, vs 80 in the nd.Linear implementation, representing a ~22% reduction in parameter count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e89b3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ae7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f9661",
   "metadata": {},
   "source": [
    "### Dataset & Preprocessing\n",
    "\n",
    "Full Dataset: (https://www.kaggle.com/datasets/qianhuan/translation?resource)\n",
    "- 5.1M English-Chinese sentence pairs\n",
    "- For the sake of the experiment, we will randomly sample 250,000 pairs \n",
    "- also sample 5000 pairs from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfee3939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5161434\n",
      "{'english': 'For greater sharpness, but with a slight increase in graininess, you can use a 1:1 dilution of this developer.', 'chinese': '为了更好的锐度，但是附带的会多一些颗粒度，可以使用这个显影剂的1：1稀释液。'}\n"
     ]
    }
   ],
   "source": [
    "train_set_path = \"dataset/translation2019zh_train.json\"\n",
    "val_set_path = \"dataset/translation2019zh_valid.json\"\n",
    "train_set = []\n",
    "val_set = [] \n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    for line in f:\n",
    "        train_set.append(json.loads(line))\n",
    "\n",
    "with open(val_set_path) as f:\n",
    "    for line in f:\n",
    "        val_set.append(json.loads(line))\n",
    "\n",
    "print(len(train_set))\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6823cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english': 'His timing when he volleys is so good.', 'chinese': '他截击空中球的时机掌握得很好。'}\n"
     ]
    }
   ],
   "source": [
    "### sample 250,000 sentences and save the data \n",
    "sampled_indices = np.random.choice(len(train_set), 250000)\n",
    "\n",
    "train_subset = [train_set[i] for i in sampled_indices]\n",
    "print(train_subset[0])\n",
    "with open('dataset/train_set_mini.pkl', 'wb') as f:\n",
    "    pickle.dump(train_subset, f)\n",
    "\n",
    "## sample 5000 pairs for validation set\n",
    "val_sampled_indices = np.random.choice(len(val_set), 5000)\n",
    "val_subset = [val_set[i] for i in val_sampled_indices]\n",
    "\n",
    "with open('dataset/val_set_mini.pkl', 'wb') as f:\n",
    "    pickle.dump(val_subset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dde9232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english': 'The present paper deals with the biology of the parasitic copepod Lernaea poly-morpha and the acquired immunity on the part of the hosts after its infeetion on silver carp and big-head.', 'chinese': '本文对鲢、鳙锚头鳋的生物学、病后获得免疫以及药物治疗进行了探讨。'}\n",
      "{'english': 'Our company is a Japanese THK linear guide set up in Qingdao Co. , Ltd. the only product-related service center.', 'chinese': '我公司是日本THK直线导轨株式会社在青岛地区设立唯一一家产品相关服务中心。'}\n"
     ]
    }
   ],
   "source": [
    "## pull the subset dataset\n",
    "with open('dataset/train_set_mini.pkl', 'rb') as f:\n",
    "    train_set_mini = pickle.load(f)\n",
    "\n",
    "with open('dataset/val_set_mini.pkl', 'rb') as f:\n",
    "    val_set_mini = pickle.load(f)\n",
    "\n",
    "print(train_set_mini[0])\n",
    "print(val_set_mini[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afe49c",
   "metadata": {},
   "source": [
    "### Creating vocabularies:\n",
    "- Maintain a vocabulary for english and chinese. \n",
    "- Limit it to words that appear at least 5 times. \n",
    "- Sequences will be represented as a list of indices, in the order in which they appear in the sentence, e.g. [0, 98, 4532, 12, 1].\n",
    "- These list of sequences will be passed to their appropriate embedding layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91a4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''\n",
    "    Get rid of all punctuation from string text\n",
    "    '''\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def get_words_from_sentence(s):\n",
    "    '''\n",
    "    Gets words from sentence \n",
    "    '''\n",
    "    return s.split(' ')\n",
    "\n",
    "def clean_en_pair(pair):\n",
    "    '''\n",
    "    Cleans the english from the pair \n",
    "    '''\n",
    "    return get_words_from_sentence(remove_punctuation(pair['english']).lower())\n",
    "\n",
    "def remove_zh_punctuation(text):\n",
    "    cleaned = re.sub(r'[，。！？【】（）《》“”‘’、]', '', text)\n",
    "    cleaned = re.sub(r'\\s+', '', cleaned)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa71b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "def get_en_vocab(train_set):\n",
    "    '''\n",
    "    get_en_dict:\n",
    "        Gets an english vocab from train_set as a dict \n",
    "    '''\n",
    "    # get only the english sentences, list of strings \n",
    "    en_sentences = [clean_en_pair(pair) for pair in train_set]\n",
    "    en_sentences_flattened = [word for sentence in en_sentences for word in sentence]\n",
    "    en_sentences_flattened = [word for word in en_sentences_flattened if word != '']\n",
    "    \n",
    "    word_counts = Counter(en_sentences_flattened)\n",
    "    # with word counts, now we limit the vocabulary to words that happen at least 5 times\n",
    "    en_vocab = {}\n",
    "    # {word: index}\n",
    "    idx = 0\n",
    "    for word in [\"<SOS>\", \"<EOS>\", \"<UNK>\"]:\n",
    "        en_vocab[word] = idx \n",
    "        idx += 1\n",
    "    for word, occurrences in word_counts.items():\n",
    "        if occurrences >= 5:\n",
    "            en_vocab[word] = idx \n",
    "            idx += 1\n",
    "    return en_vocab\n",
    "\n",
    "def get_zh_vocab(train_set):\n",
    "    '''\n",
    "    get_zh_vocab:\n",
    "        Gets an zh vocab from train_set as a dict \n",
    "    '''\n",
    "    zh_sentences = [list(remove_zh_punctuation(pair['chinese'])) for pair in train_set]\n",
    "    zh_sentences_flattened = [word for sentence in zh_sentences for word in sentence]\n",
    "\n",
    "    word_counts = Counter(zh_sentences_flattened)\n",
    "    zh_vocab = {}\n",
    "\n",
    "    idx = 0 \n",
    "    for word in [\"<SOS>\", \"<EOS>\", \"<UNK>\"]:\n",
    "        zh_vocab[word] = idx \n",
    "        idx += 1 \n",
    "    for word, occurrences in word_counts.items():\n",
    "        if occurrences >= 2: \n",
    "            zh_vocab[word] = idx \n",
    "            idx += 1 \n",
    "    return zh_vocab\n",
    "\n",
    "en_vocab = get_en_vocab(train_set_mini)\n",
    "print(len(en_vocab))\n",
    "\n",
    "zh_vocab = get_zh_vocab(train_set_mini)\n",
    "print(len(zh_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f8539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab/en_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(en_vocab, f)\n",
    "\n",
    "with open('vocab/zh_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(zh_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831a5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab/en_vocab.pkl', 'rb') as f:\n",
    "    en_vocab = pickle.load(f)\n",
    "\n",
    "with open('vocab/zh_vocab.pkl', 'rb') as f:\n",
    "    zh_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a3577",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "- Based mostly on : (https://arxiv.org/pdf/1409.3215), not completely honest to the paper\n",
    "- Model will consist of an Encoder and Decoder, passing in source sequence to encoder, and passing the hidden states from the encoder to the decoder. \n",
    "\n",
    "**Encoder**:\n",
    "- consists of an LSTM and an embedding layer. \n",
    "\n",
    "**Decoder**:\n",
    "- consists of an LSTM and an embedding layer, and a **linear layer** to output logits. \n",
    "- this linear layer is where we can place nd.Linear in place of nn.Linear\n",
    "- forward() has two settings, inference and teacher-forcing. If a \"correct label\" sentence is passed to the forward() function, it will do teacher forcing. \n",
    "\n",
    "**Attention Layer**:\n",
    "- A separate general form Luong Attention layer. It's another **linear layer** so another place where nd.Linear will be dropped in. \n",
    "\n",
    "**In total that makes 2 places where nn.Linear will be replaced by nd.Linear**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6811eb3",
   "metadata": {},
   "source": [
    "### Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b6e14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(embedding_dim, hidden_dim) # initialize an LSTM, with embedding_dim, and hidden_dim hyperparameters \n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)  # remember that sentence has to the in [word_index0, word_index1, word_index2] form\n",
    "        out , (h_n, c_n) = self.LSTM(embeds.view(len(sentence), 1, -1)) # one timestep at a time \n",
    "        return out, (h_n, c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f69687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LUONG ATTENTION LAYER\n",
    "class GeneralAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, linear_cls=nn.Linear):\n",
    "        super().__init__()\n",
    "        self.linear_layer = linear_cls(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, encoder_outputs):\n",
    "        return self.linear_layer(encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f171f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, hidden_dim, device, max_response_length, linear_cls=nn.Linear):\n",
    "        super(LuongAttnDecoder, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.linear = linear_cls(hidden_dim * 2, vocab_size) # 2x hidden dim now for result after concat attention input\n",
    "        self.device = device\n",
    "        self.general_attn_layer = GeneralAttention(hidden_dim, linear_cls)\n",
    "        self.max_response_length = max_response_length\n",
    "    \n",
    "    def word_to_tensor(self, word):\n",
    "        '''\n",
    "        takes a single wrod and gets the corresponding tensor\n",
    "        '''\n",
    "        word_lst = get_words_from_sentence(remove_zh_punctuation(word))\n",
    "        indices = [zh_vocab[word] for word in word_lst]\n",
    "        # get tensor \n",
    "        return torch.tensor(indices, dtype=torch.long).to(self.device)\n",
    "\n",
    "    def forward(self, hidden, encoder_out, sentence=None):\n",
    "        '''\n",
    "        does the forward propagation. If sentence is provided, then we do teacher-forcing. Else we assume it is inference  \n",
    "            Params:\n",
    "                hidden: the hidden state passed from the previous \n",
    "                sentence: a sentence to be used for teacher-forcing, as a tensor \n",
    "                Make sure the teacher-forcing sentence is sliced to not include the last token [:-1]\n",
    "        '''\n",
    "        # teacher-forcing training, we are going to \"undo\" vectorization]\n",
    "        all_outputs = []\n",
    "        if sentence is not None:\n",
    "            embeds_tensor = self.embeddings(sentence)\n",
    "            for word_tensor in embeds_tensor:\n",
    "                out, hidden = self.LSTM(word_tensor.view(1, 1, -1), hidden)\n",
    "                # pass encoder out to attention layer \n",
    "                attn_scores = self.general_attn_layer(encoder_out) @ hidden[0].squeeze()\n",
    "                # now with attn scores, we want to softmax the scores \n",
    "                softmaxed_scores = torch.nn.functional.softmax(attn_scores, dim=0)\n",
    "                # multiply by encoder_out\n",
    "                # now that they are softmaxed, we want to multiply by all encoder states to give a weighted tensor, we can broadcast it as well \n",
    "                weighted_encoder_hidden_states = softmaxed_scores * encoder_out.squeeze()\n",
    "                # sum the tensor \n",
    "                context = torch.sum(weighted_encoder_hidden_states, dim=0).view(1, 1, -1)\n",
    "                # concat the context vector with the hidden state \n",
    "                combined_tensor = torch.concat([context, hidden[0]], dim=-1)\n",
    "                logits = self.linear(combined_tensor)\n",
    "                all_outputs.append(logits)\n",
    "        else:\n",
    "            start_token = self.word_to_tensor('<SOS>')\n",
    "            # run through embedding layer\n",
    "            prev_char = start_token\n",
    "            for i in range(self.max_response_length):\n",
    "                if prev_char.item() == 1:\n",
    "                    break\n",
    "                embeds = self.embeddings(prev_char).to(self.device)\n",
    "                out, hidden = self.LSTM(embeds.view(1, 1, -1), hidden)\n",
    "                attn_scores = self.general_attn_layer(encoder_out) @ hidden[0].squeeze()\n",
    "                softmaxed_scores = torch.nn.functional.softmax(attn_scores, dim=0)\n",
    "                weighted_encoder_hidden_states = softmaxed_scores * encoder_out.squeeze()\n",
    "                context = torch.sum(weighted_encoder_hidden_states, dim=0).view(1, 1, -1)\n",
    "                combined_tensor = torch.concat([context, hidden[0]], dim=-1)\n",
    "                logits = self.linear(combined_tensor)\n",
    "                all_outputs.append(logits)\n",
    "                pred_idx = torch.argmax(logits, dim=2).item()\n",
    "                prev_char = torch.tensor(pred_idx, dtype=torch.long, device=self.device)\n",
    "        return torch.cat(all_outputs, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c9a1d2",
   "metadata": {},
   "source": [
    "### Training / Inference utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d1500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions to take a sentence and turn it into a tensor, adding <sos> and <eos>\n",
    "def sequence_to_tensor_en(sequence):\n",
    "    '''\n",
    "    takes sequence and converts to tensor \n",
    "    '''\n",
    "    # add \"<SOS> and <EOS>\"\n",
    "    words = get_words_from_sentence(\"<SOS> \" + remove_punctuation(sequence).lower() + \" <EOS>\")\n",
    "    \n",
    "    # convert to indices, reverting to <UNK> token\n",
    "    word_indices = [ en_vocab[word] if word in en_vocab else en_vocab[\"<UNK>\"] for word in words ]\n",
    "    return torch.tensor(word_indices, dtype=torch.long)\n",
    "    \n",
    "\n",
    "def sequence_to_tensor_zh(sequence):\n",
    "    '''\n",
    "    takes sequence and converts to chinese tensor \n",
    "    '''\n",
    "    words = ([\"<SOS>\"] + list(remove_zh_punctuation(sequence)))\n",
    "    words.append(\"<EOS>\")\n",
    "    \n",
    "    word_indices = [ zh_vocab[word] if word in zh_vocab else zh_vocab[\"<UNK>\"] for word in words ]\n",
    "    return torch.tensor(word_indices, dtype=torch.long)\n",
    "\n",
    "def zh_tensor_outputs_to_sentence(output_tensor):\n",
    "    '''\n",
    "    converts a zh_tensor to a string\n",
    "    '''\n",
    "    s = ''\n",
    "    zh_vocab_lst = list(zh_vocab.keys())\n",
    "    for word_tensor in output_tensor:\n",
    "        pred_idx = torch.argmax(word_tensor, dim=-1).item()\n",
    "        s += zh_vocab_lst[pred_idx]\n",
    "    return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b100f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, training_data, encoder, decoder, device, save_loss_file, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()), lr=lr\n",
    ")\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    # see random prediction\n",
    "    predict_en_sequence = \"I love bread\" \n",
    "    predict_en_tensor = sequence_to_tensor_en(predict_en_sequence).to(device)\n",
    "    out, predict_hidden = encoder(predict_en_tensor)\n",
    "    out = out.to(device)\n",
    "    print(zh_tensor_outputs_to_sentence(decoder.forward(predict_hidden, encoder_out=out)))\n",
    "    start_time = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        for pair in training_data:\n",
    "            count += 1\n",
    "            if count % 10000 == 0:\n",
    "                print(f\"Number of trains {count}\")\n",
    "                # print the loss\n",
    "                print(f\"Loss {total_loss / 10000}\")\n",
    "                # add the loss with count to it\n",
    "                with open(save_loss_file, 'a') as f:\n",
    "                     f.write(f'{total_loss / 10000}, {count} \\n')\n",
    "                total_loss = 0\n",
    "            english = pair['english']\n",
    "            zh = pair['chinese']\n",
    "            en_tensor = sequence_to_tensor_en(english)\n",
    "            zh_tensor = sequence_to_tensor_zh(zh)\n",
    "            # pass to device \n",
    "            en_tensor = sequence_to_tensor_en(english).to(device)\n",
    "            zh_tensor = sequence_to_tensor_zh(zh).to(device)\n",
    "\n",
    "            out, hidden = encoder.forward(en_tensor)\n",
    "            target = zh_tensor[1:]\n",
    "            predicted = decoder.forward(hidden, encoder_out=out, sentence = zh_tensor[:-1])\n",
    "            loss = nn.functional.cross_entropy(torch.squeeze(predicted), target)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        out, predict_hidden = encoder(predict_en_tensor)\n",
    "        out = out.to(device)\n",
    "        print(zh_tensor_outputs_to_sentence(decoder.forward(predict_hidden, out)))\n",
    "    print(f\"Total training time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66fb09",
   "metadata": {},
   "source": [
    "### Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b85d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RESPONSE_LENGTH=20\n",
    "EMBEDDING_DIM=32\n",
    "HIDDEN_DIM=128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f392e19",
   "metadata": {},
   "source": [
    "### EXPERIMENT 1: Performance benchmarking\n",
    "\n",
    "- Train 2 Sequence to Sequence models. The first one being a baseline model using nn.Linear, and the second being a model using nd.Linear. Both will have the same size, and trained for the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f5306",
   "metadata": {},
   "source": [
    "### Baseline model (nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236b12a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "作所作国国国国资资资个所作所作国国国资资\n",
      "Number of trains 10\n",
      "Loss 4.423114252090454\n",
      "Number of trains 20\n",
      "Loss 4.24901123046875\n",
      "<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>\n",
      "Number of trains 30\n",
      "Loss 4.1141905069351195\n",
      "Number of trains 40\n",
      "Loss 3.7753936529159544\n",
      "Number of trains 50\n",
      "Loss 3.80055718421936\n",
      "<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>\n",
      "Number of trains 60\n",
      "Loss 3.8754350900650025\n",
      "Number of trains 70\n",
      "Loss 3.710989832878113\n",
      "<UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK><UNK>\n",
      "Total training time: 8.561107873916626\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(embedding_dim=32, vocab_size=len(en_vocab), hidden_dim=128)\n",
    "decoder = LuongAttnDecoder(embedding_dim=32, vocab_size=len(zh_vocab), hidden_dim=128, device=device, max_response_length=MAX_RESPONSE_LENGTH, linear_cls=nn.Linear)\n",
    "print(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "save_loss_file = \"intermediate_steps/experiment1-baseline.txt\"\n",
    "train(3, train_set_mini, encoder, decoder, device, save_loss_file)\n",
    "torch.save(encoder.state_dict(), './trained_models/experiment1_baseline_encoder.pth')\n",
    "torch.save(decoder.state_dict(), './trained_models/experiment2_baseline_decoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
